# =========================================================
# LIMPIEZA Y NORMALIZACI√ìN DE DATASET
# =========================================================
# Objetivo del script:
# - Cargar el CSV modificado.
# - Tratar CUALQUIER cadena de texto: volverla NaN.
# - Rellenar NaN con mediana por columna.
# - Eliminar duplicados.
# - Guardar dataset limpio y m√©tricas b√°sicas para el reporte.
# =========================================================

import os
import json
import numpy as np
import pandas as pd

# ------------------------
# 1) Cargar dataset origen
# ------------------------
SRC_PATH = "../dataset/insurance_company_modified.csv"
OUT_DIR_DATA = "../data"
OUT_DIR_RES = "../results"
os.makedirs(OUT_DIR_DATA, exist_ok=True)
os.makedirs(OUT_DIR_RES, exist_ok=True)

df_raw = pd.read_csv(SRC_PATH,header=None ,low_memory=False)
print("‚úÖ Cargado:", SRC_PATH, "| Shape:", df_raw.shape)

# -----------------------------------------------------
# 2) Funci√≥n para convertir string a n√∫mero
# -----------------------------------------------------
def to_number_or_nan(x):
    # Si ya es num√©rico, lo devuelvo tal cual
    if isinstance(x, (int, float, np.number)):
        return x

    # Si es NaN de pandas/numpy, mantenerlo como NaN
    if pd.isna(x):
        return np.nan

    # Si es string, hago conversi√≥n a NaN
    if isinstance(x, str):
        s = x.strip().lower()

        # Casos que equivalen a missing
        if s in {"", "na", "n/a", "none", "null", "nan", "?", "-"}:
            return np.nan

        # Intento convertir a float
        try:
            val = float(s)
            return val
        except ValueError:
            # No es convertible -> NaN 
            return np.nan
    return np.nan

# -----------------------------------------------------------------
# 3) Aplicar conversi√≥n
# -----------------------------------------------------------------
df = df_raw.copy()

# Conteo previo de nulos y duplicados
nulls_before = int(df.isna().sum().sum())
dups_before = int(df.duplicated().sum())

# Limpieza
df = df.applymap(to_number_or_nan)

# Fuerzo que TODAS las columnas queden num√©ricas
for c in df.columns:
    df[c] = pd.to_numeric(df[c], errors="coerce")

# -------------------------------------
# 4) Rellenar NaN con mediana por columna
# -------------------------------------
cols_all_nan = []
for c in df.columns:
    if df[c].isna().all():
        cols_all_nan.append(c)
    else:
        med = df[c].median()
        df[c].fillna(med, inplace=True)

# --------------------------------
# 5) Eliminar duplicados completos
# --------------------------------
df.drop_duplicates(inplace=True)

# -------------------------------------
# 6) Detecci√≥n y correcci√≥n de outliers 
# -------------------------------------
# Para cada columna num√©rica:
# - Calculamos el rango intercuart√≠lico (IQR = Q3 - Q1)
# - Consideramos outliers los valores fuera de [Q1 - 1.5*IQR, Q3 + 1.5*IQR]
# - Los reemplazamos por la mediana de la columna

total_outliers_reemplazados = 0

for c in df.columns:
    if df[c].isna().all():
        continue  
    Q1 = df[c].quantile(0.25)
    Q3 = df[c].quantile(0.75)
    IQR = Q3 - Q1
    lower = Q1 - 1.5 * IQR
    upper = Q3 + 1.5 * IQR
    med = df[c].median()

    # Detectar valores fuera de rango
    mask_outliers = (df[c] < lower) | (df[c] > upper)
    n_outliers = mask_outliers.sum()
    total_outliers_reemplazados += int(n_outliers)

    # Reemplazar outliers por la mediana
    df.loc[mask_outliers, c] = med

print(f"\nüßπ Outliers reemplazados por mediana: {total_outliers_reemplazados} en total.")

# --------------------------------
# 6) M√©tricas de limpieza (b√°sicas)
# --------------------------------
metrics = {
    "filas_y_columnas_original": list(df_raw.shape),
    "filas_y_columnas_limpio": list(df.shape),
    "valores_nulos_antes_de_limpieza": nulls_before,
    "valores_nulos_despues_de_limpieza": int(df.isna().sum().sum()),
    "filas_duplicadas_eliminadas": int(dups_before - df.duplicated().sum()),
    "columnas_completamente_vacias": cols_all_nan,
    "total_outliers_reemplazados": total_outliers_reemplazados
}

print("üìä M√©tricas de limpieza:", metrics)

# --------------------------------
# 7) Guardar resultados
# --------------------------------
OUT_DATA_PATH = os.path.join(OUT_DIR_DATA, "insurance_clean.csv")
OUT_METRICS_PATH = os.path.join(OUT_DIR_RES, "eda_metrics.json")

df.to_csv(OUT_DATA_PATH, index=False)
with open(OUT_METRICS_PATH, "w") as f:
    json.dump(metrics, f, indent=2)

print(f"‚úÖ Guardado dataset limpio: {OUT_DATA_PATH}")
print(f"‚úÖ Guardado m√©tricas EDA:   {OUT_METRICS_PATH}")
